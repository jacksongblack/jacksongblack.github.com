---
layout: post
title: django-celery配置
category: 后台技术
describer: celery是python界比较出门异步执行框架,为了增加网站的相应速度,我们可以用django-celery把一些耗时有不需要实时响应的东西异步执行
---
## celery是个啥 

 我的站点需要很多发送email,webchat东西,但这些东西不需要用户知道发送结果,于是就想到新开进程来执行这些操作,找找python那博大的库,发现有个celery
挺复合我的需求的,celery简单来说,就是一个异步执行框架,底层是用c写的所以很安全很有效率.

## 开始集成

  所有在我的requirements.text 文件里面加入`django-celery==3.1.16` 然后`pip install -r requirements.text`,
打开`youProjectName/settions.py`文件,加入celery的相关配置.

    INSTALLED_APPS = (
            'djcelery',
            'xxxxxxxxx',
            'xxxxxxxx',
            'xxxxxxx',
            )   
    # CELERY SETTINGS
    BROKER_URL = 'redis://%s' % (CACHES_PATH) #后台的缓存地址
    CELERY_ACCEPT_CONTENT = ['json']    #接受的参数格式
    CELERY_TASK_SERIALIZER = 'json'     #任务格式
    CELERY_RESULT_SERIALIZER = 'json'   #接口json格式

  现在再在`youProjectName/celery.py`文件中配置一下内容

    from __future__ import absolute_import

    import os

    from celery import Celery

    from django.conf import settings

    # set the default Django settings module for the 'celery' program.
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'projectName.settings')

    app = Celery('projectName') #配置配置所在项目app名

    # Using a string here means the worker will not have to
    # pickle the object when using Windows.
    app.config_from_object('django.conf:settings')
    app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)
    app.conf.update(
            CELERY_RESULT_BACKEND='djcelery.backends.database:DatabaseBackend',
            )
    app.conf.update(
            CELERY_RESULT_BACKEND='djcelery.backends.cache:CacheBackend',
            )
    #增加测试项
    @app.task(bind=True)
    def debug_task(self):
        print('Request: {0!r}'.format(self.request))

现在可以在你的app中写异步执行的工具,在这之前你必须在每个app下面增加一个模块`app/tasks.py`,在这个里面,我们可以写这样的任务

    # encoding:utf-8
    from __future__ import absolute_import

    from celery import shared_task

    from Email.models import Email


    @shared_task
    def send_mass_email():
        from django.core.mail import send_mass_mail
        from JDSite import settings

        tasks = Email.objects.filter(state=0)
        messages = []
        for task in tasks:
            messages.append((task.title, task.content, settings.EMAIL_HOST_USER, [task.recipient_list.split(",")]))
        if len(messages) > 0:
            send_mass_mail(messages)

  这是个发送邮件例子,被shared_task装饰过都可以作为异步执行,但是请注意,你传入的参数,最好不要代入任何python,object_intance,因为celery无法把python对象实例进行序列化
而调用者这样使用这个方法`send_mass_email.delay()`

## 和supervisor集成

    在开发的时候我们可以这样执行celery,`python manage.py celery worker --loglevel=info`,但是在正式环境,我们可以用supervisor来部署我们celery
在ubuntu下可以用下面方法安装,supervisor是ubuntu管理器中默认有的工具,所以不用加版本地址

    sudo apt-get install supervisor

然后我们在`vi /etc/supervisor/conf.d/`中新建配置文件
    
    [program:celery]
    command=/home/release/env/bin/celery --app=JDSite.celery:app worker --loglevel=INFO
    directory=/home/jdsite/
    user=release
    numprocs=1
    stdout_logfile=/var/log/celery/celery-worker.log
    stderr_logfile=/var/log/celery/celery-worker.log
    autostart=true
    autorestart=true
    startsecs=10

    ; Need to wait for currently executing tasks to finish at shutdown.
    ; Increase this if you have very long running tasks.
    stopwaitsecs = 600

    ; When resorting to send SIGKILL to the program to terminate it
    ; send SIGKILL to its whole process group instead,
    ; taking care of its children as well.
    killasgroup=true

    ; if rabbitmq is supervised, set its priority higher
    ; so it starts first
    priority=998

配置好了后,我们需要运行`sudo supervisorctl reload`载入配置好的文件,然后再运行`sudo supervisorctl restart all`或是 `sudo supervisorctl restart program_name`
